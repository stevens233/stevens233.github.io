<!DOCTYPE html>
<html lang="zh-CN">

<!-- <style>
    .noSelect {
        -webkit-touch-callout: none; /* iOS Safari */
        -webkit-user-select: none;   /* Chrome/Safari/Opera */
        -moz-user-select: none;      /* Firefox */
        -ms-user-select: none;       /* Internet Explorer/Edge */
        user-select: none;           /* Non-prefixed version, currently supported by most modern browsers */
    }
</style> -->

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Steven的个人博客</title>
    <link rel="icon" href="/resources/steven.png" type="image/png">
    <link rel="stylesheet" href="/css/style_article.css">
</head>
<script src="script.js"></script>
<body>
    <header>
        <h1>欢迎来到Steven的博客</h1>
        <nav>
            <ul>
                <li><a href="/index.html">首页</a></li>
                <li><a href="/pages/article.html">文章</a></li>
                <li><a href="/pages/about_me.html">关于我</a></li>
                <li><a href="/pages/contact_me.html">联系方式</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section>
            <h2>卷积神经网络学习总结</h2>
            <!-- 文章列表-->
            <article>
                <p style="margin-top:0pt; margin-bottom:0pt; text-align:center; font-size:20pt;"><strong><span style="font-family:宋体;">卷积神经网络（</span></strong><strong>CNN</strong><strong><span style="font-family:宋体;">）</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>1.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">准备数据集：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">收集和处理数据，通常包括加载数据、标准化（例如，图像像素值缩放到</span>0-1<span style="font-family:宋体;">）、增强（如旋转、缩放图像等）和划分训练</span>/<span style="font-family:宋体;">验证</span>/<span style="font-family:宋体;">测试集。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>2.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">定义</span></strong><strong>CNN</strong><strong><span style="font-family:宋体;">架构：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>1. <span style="font-family:宋体;">输入层：接受原始数据（如图像）。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>2. <span style="font-family:宋体;">卷积层：通过卷积核提取特征。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>3. <span style="font-family:宋体;">激活层：如</span>ReLU<span style="font-family:宋体;">，引入非线性。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>4. <span style="font-family:宋体;">池化层：降采样，减少参数数量和计算量。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>5. <span style="font-family:宋体;">全连接层：传统的神经网络层，用于分类或回归输出。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>6. <span style="font-family:宋体;">输出层：根据任务类型（分类或回归）产生输出。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>3.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">选择编译参数：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>1. <span style="font-family:宋体;">损失函数：如交叉熵（分类）或均方误差（回归）。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>2. <span style="font-family:宋体;">优化器：如</span>SGD<span style="font-family:宋体;">、</span>Adam<span style="font-family:宋体;">等。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>3. <span style="font-family:宋体;">评价指标：如准确率。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>4.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">训练模型：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>1. <span style="font-family:宋体;">使用训练数据训练网络，包括前向传播和反向传播。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>2. <span style="font-family:宋体;">通过多个周期（</span>epochs<span style="font-family:宋体;">）训练，调整权重以最小化损失函数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>5.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">评估模型：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>1. <span style="font-family:宋体;">使用验证集和测试集评估模型的性能。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>2. <span style="font-family:宋体;">调整模型参数或结构以改善性能。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>6.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">模型部署（可选）：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">将训练好的模型部署到实际应用中。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:16pt;"><strong><span style="font-family:宋体;">反向传播（</span></strong><strong>Backpropagation</strong><strong><span style="font-family:宋体;">）</span></strong><span style="font-family:宋体; font-size:10.5pt;">是一种用于训练人工神经网络的算法，特别是在关于梯度下降优化算法的上下文中。其基本原理可以概括为以下几个步骤：</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>1.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">前向传播：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">数据在神经网络中从输入层通过隐藏层传递到输出层。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">在每一层，数据经过加权求和和激活函数处理。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>2.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">计算损失：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">在网络的输出层，损失函数计算预测值和真实值之间的差距。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>3.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">反向传播误差：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">算法计算损失函数相对于网络参数（通常是权重和偏置）的梯度。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">这是通过应用链式法则从输出层反向到输入层逐层进行的。对每层，计算损失相对于该层权重的偏导数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">实际上，这意味着算法计算每个输出误差是如何随着该层权重的变化而变化的，并且这个过程会继续传递到网络的更早层。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>4.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">更新权重和偏置：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">使用梯度下降或其他优化算法，根据计算出的梯度来更新网络的权重和偏置。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">通常，这个步骤是通过从原始权重中减去梯度乘以学习率来完成的。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:14pt;"><strong>5.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">迭代优化：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">上述过程在训练集上多次迭代，每次迭代都会使网络预测更接近实际标签。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; text-indent:21pt;"><span style="font-family:宋体;">在神经网络中，每一层都可以被视为一个函数，这些函数层层嵌套形成了整个网络。在反向传播算法中，我们从最后一层（通常是损失函数）开始，对前面的每一层进行逐层求导，最终得到第一层的梯度。这个过程利用了链式法则，它是微积分中的一个基本原则，用于计算复合函数的导数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; text-indent:21pt;"><span style="font-family:宋体;">具体来说，对于每一层&nbsp;</span>Li<span style="font-family:宋体;">，它的输出是下一层&nbsp;</span>Li+1<span style="font-family:宋体;">的输入。我们可以计算损失函数相对于&nbsp;</span>Li<span style="font-family:宋体;">的输出的偏导数，然后使用链式法则将这个偏导数传递回&nbsp;</span>LiLi<span style="font-family:宋体;"> 的输入，也就是&nbsp;</span>Li<span style="font-family:宋体;">&minus;</span>1<span style="font-family:宋体;">的输出。这样，我们就可以逐层向后计算每层权重的梯度。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; text-indent:21pt;"><span style="font-family:宋体;">这个过程从输出层开始，一直反向传播到输入层，允许我们根据损失函数计算每个权重的梯度，从而有效地训练神经网络。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:16pt;"><strong>CNN</strong><strong><span style="font-family:宋体;">流程：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>1.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">卷积：</span></strong><span style="font-family:宋体;">使用多个过滤器对输入数据进行卷积操作，提取特征。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>2.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">激活函数：</span></strong><span style="font-family:宋体;">应用非线性激活函数（如</span>ReLU<span style="font-family:宋体;">）。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>3.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">池化（可选）：</span></strong><span style="font-family:宋体;">进行池化操作（如最大池化），以降低特征维度并减少计算。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>4.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">重复卷积和池化（可选）：</span></strong><span style="font-family:宋体;">根据需要多次重复卷积和池化操作。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>5.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">展平：</span></strong><span style="font-family:宋体;">将多维的卷积或池化输出展平成一维向量。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>6.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">全连接层：</span></strong><span style="font-family:宋体;">通过一个或多个全连接层对特征进行加权求和，可能再次应用激活函数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>7.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">输出层：</span></strong><span style="font-family:宋体;">产生最终输出，这可能是类别概率（分类问题）或其他形式的输出。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>8.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">损失函数：</span></strong><span style="font-family:宋体;">计算网络输出和实际标签之间的损失。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>9.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">反向传播：</span></strong><span style="font-family:宋体;">通过损失函数对网络中每层的权重进行偏导数的计算。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>10.&nbsp;</strong><strong><span style="font-family:宋体;">梯度下降：</span></strong><span style="font-family:宋体;">根据计算的梯度更新网络权重。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>11.&nbsp;</strong><strong><span style="font-family:宋体;">迭代优化：</span></strong><span style="font-family:宋体;">重复整个过程，通过多个</span>epoch<span style="font-family:宋体;">的训练来优化网络性能。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">补充几个可能的遗漏点：</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>1.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">初始化：</span></strong><span style="font-family:宋体;">在训练开始前，网络中的权重需要进行初始化。权重初始化的策略（如随机初始化、</span>Xavier<span style="font-family:宋体;">初始化等）对模型的训练和收敛速度有重要影响。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>2.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">正则化：</span></strong><span style="font-family:宋体;">为了防止过拟合，可能会在</span>CNN<span style="font-family:宋体;">中使用正则化技术，如</span>Dropout<span style="font-family:宋体;">、</span>L1/L2<span style="font-family:宋体;">正则化等。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>3.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">批量归一化（</span></strong><strong>Batch Normalization</strong><strong><span style="font-family:宋体;">）：</span></strong><span style="font-family:宋体;">这是一种用于加速训练过程并提高模型稳定性的技术，通常在卷积层和激活函数之间应用。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>4.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">超参数调优：</span></strong>CNN<span style="font-family:宋体;">的性能很大程度上取决于超参数的选择，如学习率、批大小、</span>epoch<span style="font-family:宋体;">数量、卷积核大小和数量等。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>5.</strong><strong>&nbsp;&nbsp;</strong><strong><span style="font-family:宋体;">数据增强：</span></strong><span style="font-family:宋体;">在训练图像处理模型时，通常会使用数据增强技术来增加数据集的多样性，如旋转、缩放、裁剪等。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <ol start="6" type="1" style="margin:0pt; padding-left:0pt;">
                    <li style="list-style-position:inside;"><strong><span style="font-family:宋体;">&nbsp;</span></strong><strong><span style="font-family:宋体;">评估指标：</span></strong><span style="font-family:宋体;">除了损失函数，还会使用其他评估指标（如准确率、召回率、</span>F1<span style="font-family:宋体;">分数等）来评价模型性能。</span></li>
                </ol>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt; font-size:15pt;"><strong>vgg16</strong><strong><span style="font-family:宋体;">模型的结构分析：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong><span style="font-family:宋体;">代码：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt; text-align:left; line-height:18pt; widows:2; orphans:2; background-color:#1f1f1f;"><span style="font-family:Menlo; font-size:12pt; color:#c586c0; background-color:#1f1f1f;">for</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">&nbsp;</span><span style="font-family:Menlo; font-size:12pt; color:#9cdcfe; background-color:#1f1f1f;">name</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">,&nbsp;</span><span style="font-family:Menlo; font-size:12pt; color:#9cdcfe; background-color:#1f1f1f;">layer</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">&nbsp;</span><span style="font-family:Menlo; font-size:12pt; color:#dcdcaa; background-color:#1f1f1f;">in</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">&nbsp;</span><span style="font-family:Menlo; font-size:12pt; color:#9cdcfe; background-color:#1f1f1f;">vgg16</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">.</span><span style="font-family:Menlo; font-size:12pt; color:#dcdcaa; background-color:#1f1f1f;">named_children</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">():</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt; text-indent:21pt; text-align:left; line-height:18pt; widows:2; orphans:2; background-color:#1f1f1f;"><span style="font-family:Menlo; font-size:12pt; color:#dcdcaa; background-color:#1f1f1f;">print</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">(</span><span style="font-family:Menlo; font-size:12pt; color:#569cd6; background-color:#1f1f1f;">f</span><span style="font-family:Menlo; font-size:12pt; color:#ce9178; background-color:#1f1f1f;">&quot;Layer Name:&nbsp;</span><span style="font-family:Menlo; font-size:12pt; color:#569cd6; background-color:#1f1f1f;">{</span><span style="font-family:Menlo; font-size:12pt; color:#9cdcfe; background-color:#1f1f1f;">name</span><span style="font-family:Menlo; font-size:12pt; color:#569cd6; background-color:#1f1f1f;">}</span><span style="font-family:Menlo; font-size:12pt; color:#ce9178; background-color:#1f1f1f;">&nbsp;</span><span style="font-family:Menlo; font-size:12pt; color:#d7ba7d; background-color:#1f1f1f;">\n</span><span style="font-family:Menlo; font-size:12pt; color:#ce9178; background-color:#1f1f1f;">Layer:&nbsp;</span><span style="font-family:Menlo; font-size:12pt; color:#569cd6; background-color:#1f1f1f;">{</span><span style="font-family:Menlo; font-size:12pt; color:#9cdcfe; background-color:#1f1f1f;">layer</span><span style="font-family:Menlo; font-size:12pt; color:#569cd6; background-color:#1f1f1f;">}</span><span style="font-family:Menlo; font-size:12pt; color:#d7ba7d; background-color:#1f1f1f;">\n</span><span style="font-family:Menlo; font-size:12pt; color:#ce9178; background-color:#1f1f1f;">&quot;</span><span style="font-family:Menlo; font-size:12pt; color:#cccccc; background-color:#1f1f1f;">)</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong><span style="font-family:宋体;">输出：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">Layer Name: features</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">Layer: Sequential(</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (1): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (3): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (6): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (8): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (11): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (13): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (15): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (18): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (20): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (22): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (25): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (27): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (29): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">Layer Name: avgpool</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">Layer: AdaptiveAvgPool2d(output_size=(7, 7))</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">Layer Name: classifier</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">Layer: Sequential(</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (0): Linear(in_features=25088, out_features=4096, bias=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (1): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (2): Dropout(p=0.5, inplace=False)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (3): Linear(in_features=4096, out_features=4096, bias=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (4): ReLU(inplace=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (5): Dropout(p=0.5, inplace=False)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp; (6): Linear(in_features=4096, out_features=1000, bias=True)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">)</p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong><span style="font-family:宋体;">解析：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">这个模型的结构是经典的&nbsp;</span>VGG16 <span style="font-family:宋体;">模型，由三个部分组成：</span>features<span style="font-family:宋体;">（特征提取层）、</span>avgpool<span style="font-family:宋体;">（全局平均池化层） 和&nbsp;</span>classifier<span style="font-family:宋体;">（分类器）。下面是对每个部分的详细分析：</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>Features</strong><strong><span style="font-family:宋体;">（特征提取层）</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">特征提取层由一系列卷积层（</span>Conv2d<span style="font-family:宋体;">）、激活函数（</span>ReLU<span style="font-family:宋体;">）和池化层（</span>MaxPool2d<span style="font-family:宋体;">）组成，用于提取图像的高级特征。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong><span style="font-family:宋体;">卷积层与激活函数：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>1-2 <span style="font-family:宋体;">层：输入为&nbsp;</span>3 <span style="font-family:宋体;">通道（</span>RGB<span style="font-family:宋体;">），输出为&nbsp;</span>64 <span style="font-family:宋体;">通道，卷积核大小为&nbsp;</span>3x3<span style="font-family:宋体;">，步幅为&nbsp;</span>1<span style="font-family:宋体;">，填充为&nbsp;</span>1<span style="font-family:宋体;">，使用&nbsp;</span>ReLU <span style="font-family:宋体;">激活函数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>3-4 <span style="font-family:宋体;">层：输入为&nbsp;</span>64 <span style="font-family:宋体;">通道，输出为&nbsp;</span>64 <span style="font-family:宋体;">通道，同样的卷积核和激活函数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>5 <span style="font-family:宋体;">层：最大池化层，将特征图尺寸减半。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>6-7 <span style="font-family:宋体;">层：输入为&nbsp;</span>64 <span style="font-family:宋体;">通道，输出为&nbsp;</span>128 <span style="font-family:宋体;">通道，卷积核和激活函数相同。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>8 <span style="font-family:宋体;">层：最大池化层。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>9-11 <span style="font-family:宋体;">层：输入为&nbsp;</span>128 <span style="font-family:宋体;">通道，输出为&nbsp;</span>256 <span style="font-family:宋体;">通道。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>12 <span style="font-family:宋体;">层：最大池化层。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>13-15 <span style="font-family:宋体;">层：输入为&nbsp;</span>256 <span style="font-family:宋体;">通道，输出为&nbsp;</span>512 <span style="font-family:宋体;">通道。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>16 <span style="font-family:宋体;">层：最大池化层。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>17-19 <span style="font-family:宋体;">层：输入为&nbsp;</span>512 <span style="font-family:宋体;">通道，输出为&nbsp;</span>512 <span style="font-family:宋体;">通道。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>20 <span style="font-family:宋体;">层：最大池化层。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>21-23 <span style="font-family:宋体;">层：输入为&nbsp;</span>512 <span style="font-family:宋体;">通道，输出为&nbsp;</span>512 <span style="font-family:宋体;">通道。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>24 <span style="font-family:宋体;">层：最大池化层。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">这些层通过多次卷积和池化逐步提取图像的多层次特征，同时减少特征图的尺寸，提高计算效率。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>Avgpool</strong><strong><span style="font-family:宋体;">（全局平均池化层）</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;</span>AdaptiveAvgPool2d<span style="font-family:宋体;">：输出大小为&nbsp;</span>7x7 <span style="font-family:宋体;">的特征图。这一层的作用是将每个通道的特征图尺寸固定为&nbsp;</span>7x7<span style="font-family:宋体;">，以便与后续的全连接层对接。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong>Classifier</strong><strong><span style="font-family:宋体;">（分类器）</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">分类器部分由全连接层（</span>Linear<span style="font-family:宋体;">）、激活函数（</span>ReLU<span style="font-family:宋体;">）和&nbsp;</span>Dropout <span style="font-family:宋体;">层组成，主要用于分类任务。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong><span style="font-family:宋体;">全连接层与激活函数：</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>1 <span style="font-family:宋体;">层：输入特征数为&nbsp;</span>25088<span style="font-family:宋体;">（</span>512 * 7 * 7<span style="font-family:宋体;">），输出特征数为&nbsp;</span>4096<span style="font-family:宋体;">，使用&nbsp;</span>ReLU <span style="font-family:宋体;">激活函数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>2 <span style="font-family:宋体;">层：</span>Dropout <span style="font-family:宋体;">层，丢弃率为&nbsp;</span>50%<span style="font-family:宋体;">。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>3 <span style="font-family:宋体;">层：输入特征数为&nbsp;</span>4096<span style="font-family:宋体;">，输出特征数为&nbsp;</span>4096<span style="font-family:宋体;">，使用&nbsp;</span>ReLU <span style="font-family:宋体;">激活函数。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>4 <span style="font-family:宋体;">层：</span>Dropout <span style="font-family:宋体;">层，丢弃率为&nbsp;</span>50%<span style="font-family:宋体;">。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-family:宋体;">第&nbsp;</span>5 <span style="font-family:宋体;">层：输入特征数为&nbsp;</span>4096<span style="font-family:宋体;">，输出特征数为&nbsp;</span>1000<span style="font-family:宋体;">，不使用激活函数（通常在损失函数中会包含&nbsp;</span>softmax <span style="font-family:宋体;">激活）。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><span style="font-family:宋体;">这些层用于将特征图展平成向量，并进行逐层分类，最终输出一个&nbsp;</span>1000 <span style="font-family:宋体;">维的向量（通常对应&nbsp;</span>ImageNet <span style="font-family:宋体;">数据集的&nbsp;</span>1000 <span style="font-family:宋体;">个类别）。</span></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">&nbsp;</p>
                <p style="margin-top:0pt; margin-bottom:0pt;"><strong><span style="font-family:宋体;">总结</span></strong></p>
                <p style="margin-top:0pt; margin-bottom:0pt;">VGG16 <span style="font-family:宋体;">通过层次化的卷积和池化操作提取图像的高级特征，然后通过全连接层进行分类。其设计理念是使用小卷积核（</span>3x3<span style="font-family:宋体;">）和较深的网络结构（</span>16 <span style="font-family:宋体;">层），在保持计算效率的同时提高特征提取能力。</span></p>
            </article>
            <!-- 更多文章-->
        </section>
    </main>

    <footer>
        <p>版权所有 &copy; 2024 Steven的博客</p>
    </footer>

</body>
</html>